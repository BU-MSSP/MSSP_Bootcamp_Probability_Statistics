\pdfminorversion=4
\documentclass[handout,fleqn,aspectratio=169]{beamer}

\usepackage{pgfpages}
\pgfpagesuselayout{resize to}[a4paper,landscape,border shrink=5mm]

\mode<presentation>
{
  \usetheme{default}
  \usecolortheme{default}
  \usefonttheme{default}
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[frame number]  % or "page number"
  \setbeamercolor{frametitle}{fg=white}
  \setbeamercolor{footline}{fg=black}
} 

\usepackage[english]{babel}
%\usepackage[utf8x]{inputenc}
\usepackage{tikz}
\usepackage{courier}
\usepackage{array}
\usepackage{bold-extra}
\usepackage{minted}
\usepackage[thicklines]{cancel}
\usepackage{fancyvrb}
\usepackage{kotex}
\usepackage{paralist}
\usepackage{collectbox}
\usepackage{booktabs}
\usepackage{nccmath}
\usepackage{bm}

%\usepackage[fleqn]{amsmath}

\setbeamercolor{block body alerted}{bg=alerted text.fg!10}
\setbeamercolor{block title alerted}{bg=alerted text.fg!20}
\setbeamercolor{block body}{bg=structure!10}
\setbeamercolor{block title}{bg=structure!20}
\setbeamercolor{block body example}{bg=green!10}
\setbeamercolor{block title example}{bg=green!20}
\setbeamertemplate{blocks}[rounded][shadow]

\xdefinecolor{dianablue}{rgb}{0.18,0.24,0.31}
\xdefinecolor{darkblue}{rgb}{0.1,0.1,0.7}
\xdefinecolor{darkgreen}{rgb}{0,0.5,0}
\xdefinecolor{darkgrey}{rgb}{0.35,0.35,0.35}
\xdefinecolor{darkorange}{rgb}{0.8,0.5,0}
\xdefinecolor{darkred}{rgb}{0.7,0,0}
\definecolor{darkgreen}{rgb}{0,0.6,0}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\newcommand{\progressbar}{
\pgfmathsetmacro{\theta}{360/\inserttotalframenumber*\inserttotalframenumber}
\begin{tikzpicture}[scale=0.035]
\fill[yellow] (0,0) circle (9);
\fill[red] (0,0) -- (9,0) arc (0:-\theta:9);
\fill[white] (0,0) circle (5);
\end{tikzpicture}
}

%\setbeamertemplate{footline}{\hfill \progressbar}

\title[]{Lecture 8: Random Processes, Part II}
\author{Yi, Yung (이융)}
\institute{EE210: Probability and Introductory Random Processes\\ KAIST EE}
\date{MONTH DAY, 2021}

\usetikzlibrary{shapes.callouts}

\input{../mymath}


\begin{document}

\input{../mydefault}

\logo{\pgfputat{\pgfxy(0.11, 7.4)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\mbox{\hspace{-8 cm}\includegraphics[height=0.7 cm]{../kaist_ee.png}
}}}}

\begin{frame}
  \titlepage
\end{frame}

\logo{\pgfputat{\pgfxy(0.11, 7.4)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\mbox{\hspace{-8 cm}\includegraphics[height=0.7 cm]{../kaist_ee.png}
}}}}

% % Uncomment these lines for an automatically generated outline.
% \begin{frame}{Outline}
% % \tableofcontents
% \plitemsep 0.1in
% \bci
% \item 

% \item 
% \eci
% \end{frame}

% START START START START START START START START START START START START START

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Roadmap}

\plitemsep 0.1in

\bci 

% \item A lot of applications in engineering systems


% \bigskip

{\scriptsize
\item \bluef{Basics on Random Process}
\item \bluef{Bernoulli Process}
\item \bluef{Poisson Process}
\item \bluef{Use of Bernoulli and Poisson Processes}
}


\item \redf{Markov Chain}
\bci
\item \redf{Definition, Transition Probability Matrix, State Transition Diagram}
\item Classification of States
\item Steady-state Behaviors and Stationary Distribution
\item Transient Behaviors
\eci
\eci 

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Recap and Markov Chain}

- Assume discrete times $n=1, 2, \ldots$
\plitemsep 0.05in
\bci 
\item Random process: A sequence of $X_1, X_2, X_3, \cdots $

\item<2-> ``Simplest'' random process

\bci
\item<3-> Process without memory
\aleq{
\cprob{X_{n} = i_{n} \mid X_{n-1} = i_{n-1},X_{n-2} = i_{n-2},X_{n-3} = i_{n-3}, \ldots, X_1 = i_1 } = \cprob{X_{n} = i_{n}}
}
\item<4-> \redf{Bernoulli process}
\eci

\item<5-> A random process that is a little more complex than the above?
\bci
\item<6-> Process that depends only on ``yesterday", not the entire history
\aleq{
\cprob{X_{n} = i_{n} \mid X_{n-1} = i_{n-1},X_{n-2} = i_{n-2},X_{n-3} = i_{n-3}, \ldots, X_1 = i_1 } = \cprob{X_{n} = i_{n} \mid X_{n-1} = i_{n-1} }
}

\item<7-> \redf{Markov chain}

\item<7-> One of the most popular random processes in engineering
\eci

\eci 
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example: Machine Failure, Repair, and Replacement}

\plitemsep 0.1in
\bci 
\item A machine: working or broken down on a given day. 
\bci
\item If working, break down in the next day w.p. $b$, and continue working w.p. $1-b.$

\item If broken down, it will be repaired and be working in the next day w.p. $r,$ and continue to be broken down w.p. $1-r.$ 
\eci

\item<2-> $X_n \in \{1,2 \}$: status of the machine, 1: working and 2: broken down

\item<3-> $(X_n)_{n=1}^\infty$: A random process satisfying: for any $n \ge 1,$
\aleq{
\cprob{X_{n+1} = 1 | X_{n} = 1} = 1-b, \quad \cprob{X_{n+1} = 2 | X_{n} = 1} = b \cr
\cprob{X_{n+1} = 1 | X_{n} = 2} = r, \quad \cprob{X_{n+1} = 2 | X_{n} = 2} = 1-r 
}

\item<4-> What will happen at $(n+1)$-th day depends only on what happens at $n$-th day? 
\eci 
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Markov Chain: Definition}

\plitemsep 0.1in

\bci 
\item<2-> \defi Let $X_1, \ldots, X_n, \ldots$ be a sequence of random
  variables taking values in some finite space
  $\set{S}=\{1, 2, \ldots, m\}$, such that   for all $i,j \in
  \set{S},$ $n\geq 0,$ the following \bluef{Markov property} is satisfied:
\aleq{
\cprob{X_{n+1} = j \vert X_{n} = i} = \cprob{X_{n+1} = j
      \vert X_n = i, X_{n-1}=i_{n-1}, \ldots, X_0=i_0}, 
}

\item<3-> For any fixed $n,$ the future of the process after $n$ is {\red independent}
    of $\{X_1, \ldots, X_n \},$ {\red given} $X_n$ (i.e., depends only on $X_n$)

\item<4-> The value that $X_n$ can take is called \redf{`state'.} Thus, the space $\set{S}$ is called \redf{\em state space}.

\item<5-> \redf{Time homogeneity.} The probability $\cprob{X_{n+1} = j \vert X_{n} = i}$ does NOT depends on $n.$ 

\medskip
\onslide<6->{Thus, for any $n \ge 0,$ we introduce a simple notation $p_{ij}$
\aleq{
p_{ij} &\eqdef\cprob{X_{n+1} = j \vert X_{n} = i}
}}

\eci 
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Transition Prob. Matrix and State Transition Diagram}

\plitemsep 0.05in

\bci 
\item<2-> \redf{Transition Probability Matrix.} Consider a $m \times m$ matrix $\mat{P}=[p_{ij}],$ where $p_{ij} \eqdef \cprob{X_{n+1} = j \vert X_{n} = i}$

\item<3-> Machine example.
\aleq{
p_{11} &= \cprob{X_{n+1} = 1 | X_{n} = 1} = 1-b,  & p_{12} = \cprob{X_{n+1} = 2 | X_{n} = 1} = b \cr
p_{21} &= \cprob{X_{n+1} = 1 | X_{n} = 2} = r,  & p_{22} = \cprob{X_{n+1} = 2 | X_{n} = 2} = 1-r 
}

\mytwocols{0.3}
{
\small
- Transition probability matrix

\bigskip
\centering
\mypic{0.3}{L9_machine_tpm.png}
}
{
\small
- State transition diagram

\medskip
\centering
\mypic{0.8}{L9_machine_std.png}
}

\item<4-> Both are the complete description of Markov chain.

\item<5-> $\sum_{j=}^m p_{ij} =1$ (for each row $i$, the column sum = 1)
\eci 
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Spider-Fly example}

% \mytwocols{0.6}
% {
\small
\plitemsep 0.05in

\bci 
\item A fly moves along a line in unit increments.

\item<2-> At each time, it moves one unit (i) left w.p. 0.3, (ii) right w.p. 0.3 and (iii) stays in place w.p. 0.4, independent of the past history of movements. 

\item<3-> Two spiders lurk at positions 1 and 4: if the fly lands there, it is captured by the spider, and the process terminates. Assume that the fly starts in a position between 1 and $4.$

\bigskip
\item<4-> $X_n$: position of the fly. Please draw the state transition diagram and find the transition probability matrix. 

\eci 
\onslide<5->{
\centering
\mypic{0.7}{L9_spider_fly.png}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Probability of a Sample Path}

\redf{(Q)} What is the probability of a sample path in a Markov chain?

\small
\aleq{
\onslide<2->{&\cbprob{ X_0 = i_0, X_{1} = i_{1}, X_{2} = i_{2},\ldots, X_{n} = i_{n}}} \cr
\onslide<3->{&= \cbprob{X_{n} = i_{n}|  X_0 = i_0, X_{1} = i_{1}, \ldots, X_{n-1} = i_{n-1}}\cdot \cbprob{X_0 = i_0, X_{1} = i_{1}, \ldots, X_{n-1} = i_{n-1}}}\cr
\onslide<4->{&= p_{i_{n-1}i_n} \cdot \cbprob{X_0 = i_0, X_{1} = i_{1}, \ldots, X_{n-1} = i_{n-1}} = \cprob{X_0 = i_0} \cdot p_{i_0 i_1}\cdot p_{i_1 i_2}\cdots p_{i_{n-1} i_n}}
}

% \mytwocols{0.6}
% {
\plitemsep 0.05in

\bci 
\item<5-> Spider-Fly example
\aleq{
\onslide<5->{\cprob{X_0 = 2, X_1=2, X_2=2, X_3 = 3,  X_4=4}} \onslide<6->{= \cprob{X_0=2} p_{22} p_{22} p_{23} p_{34} = \cprob{X_0=2} (0.4)^2 (0.3)^2}
}
\eci 

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Probability after $n$ Steps}

\redf{(Q)} What is the probability that my state is $i$, starting from $i$ after $n$ steps?

\plitemsep 0.05in

\bci 
\item<2-> $n$-step transition probability 
$$
r_{ij}(n) \eqdef \cprob{X_n = j \mid X_0 =i}
$$
\item<3-> Recursive formula, starting with $r_{ij}(1) = p_{ij}$

\myvartwocols{0.4}{0.6}{0.38}
{
\small
\aleq{
\onslide<3->{&r_{ij}(n) = \cprob{X_n = j \mid X_0 =i} =} \cr
\onslide<4->{&\sum_{k=1}^m \cprob{X_{n-1}=k | X_0=i} \cprob{X_n = j | X_{n-1}=k, X_0=i}} \cr
\onslide<5->{&= \sum_{k=1}^m r_{ik}(n-1) p_{kj}}
}
}
{
\centering
\mypic{0.9}{L9_nstep.png}
}

\eci 

\end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}{Classification of States}

% \begin{center}
% \mypic{0.5}{L9_spider_fly.png}
% \end{center}
% \vspace{-0.8cm}
% \plitemsep 0.05in
% \bci
% \item See the difference between the states `1' and `2'?

% \item State `1' and `4': 

% \item State `1': 
% \eci



% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Roadmap}

\plitemsep 0.1in

\bci 

% \item A lot of applications in engineering systems


% \bigskip

{\scriptsize
\item \bluef{Basics on Random Process}
\item \bluef{Bernoulli Process}
\item \bluef{Poisson Process}
\item \bluef{Use of Bernoulli and Poisson Processes}
}


\item \redf{Markov Chain}
\bci
\item \bluef{Definition, Transition Probability Matrix, State Transition Diagram}
\item \redf{Classification of States}
\item Steady-state Behaviors and Stationary Distribution
\item Transient Behaviors
\eci
\eci 

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Examples: Different States and Classes}

\myvartwocols{0.3}{0.6}{0.38}
{
\small
\plitemsep 0.05in
\bci
\item Classes
\bci
\item<2-> 3 can only be reached from 3
\item<3-> 1 and 2 can reach each other but no other state
\item<4-> 4, 5, and 6 all reach each other.
\item<5-> Divide into three classes: $\{ 3\}, \{1,2 \}, \{4,5,6 \}$
\item<6-> \redf{Insight 1.} \bluef{Multiple classes may exist.}
\eci
\eci
}
{
\vspace{-0.5cm}
\begin{center}
\mypic{0.95}{L9_class_ex.png}
\end{center}
}

\small
\plitemsep 0.05in
\bci
\item<7-> Difference between 1 and 3
\bci
\item<8-> 1: If I start from 1, visit 1 infinite times.
\item<9-> 3: If I start from 3, visit 3 only finite times (move to other classes and don't return). 
\item<10-> \redf{Insight 2.} \bluef{Some states are visited infinite times, but some states are not.}
\eci

\item<11-> State 2 will share the above properties with 1 (similarly, 4,5, and 6)
\item<12-> \redf{Insigt 3.} \bluef{States in the same class share some properties.}
\eci
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Classification of States (1)}

\myvartwocols{0.35}{0.6}{0.38}
{
\small
\plitemsep 0.05in
\bci
\item<2-> \defi State $j$ is \bluef{accessible} from state $i$, if for some $n$ $r_{ij}(n) >0.$
\bci
\item<3-> 6 is accessible from 3, but not the other way around.  
\eci
\item<4-> \defi If $i$ is accessible from $j$ and $j$ is accessible from $i,$ we say that $i$ communicates with $j.$
%  denoted by $i \leftrightarrow j.$
\bci
\item<5-> $1 \leftrightarrow 2$, but $3$ does not communicate with $5.$
\eci
\eci
}
{
\vspace{-0.3cm}
\begin{center}
\mypic{0.95}{L9_class_ex.png}
\end{center}
}

\small
\plitemsep 0.05in
\bci
 \item<6-> \defi Let $A(i) = \{\text{states accessible from $i$} \}.$ State $i$ is \bluef{recurrent}, if 
 $\forall j \in A(i),$ $i$ is also accessible from $j.$  In other words, ``I communicate with all of my neighbors!"
\bci
  \item<7-> A state that is not recurrent is \bluef{transient.}  
  \item<8-> 2 is recurrent? Yes. 3 is recurrent? No. 
%   $A(1) = \{2\}.$ 1 is also accessible from 2, so 1 is recurrent. Similarly, 2 is recurrent. 
%  \item $A(3) = \{1, 3, 4, 5 \}$, but 3 is NOT accessible from 4. So, 3 is transient. 
 \item<9-> If we start from a recurrent state $i$, then there is always some probability of returning to $i.$ It means that, given enough time, it is certain that it returns to $i.$ 
\eci
\eci
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Classification of States (2)}

\myvartwocols{0.8}{0.65}{0.34}
{
\small
\plitemsep 0.05in
\bci
%\item For a recurrent state $i,$ $A(i) = A(j)$ for all $j$ that belong to $A(i).$

\item A set of recurrent states which communicate with each other form a \redf{class.}

\item<2-> Markov chain decomposition
\bci
\plitemsep 0.05in
\item<2-> A MC can be decomposed into one or more recurrent classes, plus possibly some transient states.
\item<3-> A recurrent state is accessible from all states in its class, but it not accessible from recurrent states in other classes.
\item<4-> A transient state is not accessible from any recurrent state.
\item<5-> At least one, possibly more, recurrent states are accessible from a given transient state. 
\eci 

\item<6-> The MC with only a single recurrent class is said to be \redf{irreducible} (더이상 분해할 수 없는).

\eci
}
{
%\vspace{-0.3cm}
\begin{center}
\mypic{0.99}{L9_recurrent_transient_ex.png}
\end{center}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Periodicity}

\plitemsep 0.1in
\bci

\item<2-> The states in a recurrent class are periodic if they can be grouped into $d>1$ groups so that all transitions from one group lead to the next group.

\item<3-> A recurrent class that is not periodic is said to be aperiodic. 
\eci

\begin{center}
\mypic{0.3}{L9_periodic.png}
\end{center}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Roadmap}

\plitemsep 0.1in

\bci 

% \item A lot of applications in engineering systems


% \bigskip

{\scriptsize
\item \bluef{Basics on Random Process}
\item \bluef{Bernoulli Process}
\item \bluef{Poisson Process}
\item \bluef{Use of Bernoulli and Poisson Processes}
}


\item \redf{Markov Chain}
\bci
\item \bluef{Definition, Transition Probability Matrix, State Transition Diagram}
\item \bluef{Classification of States}
\item \redf{Steady-state Behaviors and Stationary Distribution}
\item Transient Behaviors
\eci
\eci 

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{$n$-step transition prob.: $r_{ij}(n)$ for large $n$}

\mytwocols{0.6}
{
\bci
\item<2-> \small Convergence irrespective of the starting state
\eci


\medskip
\centering
\mypic{0.95}{L9_inftysteps1.png}
}
{
\bci
\item<3-> \small Convergence depending on the starting state
\eci


\medskip
\centering
\mypic{0.95}{L9_inftysteps2.png}
}

\onslide<4->{\redf{(Q)} Under what conditions, convergence occurs? If so, how does it depend on the starting state?}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Steady-state behavior}

\mytwocols{0.7}
{
\plitemsep 0.1in

\bci
\item $r_{ij}(n) \xrightarrow{n \rightarrow \infty} \pi_j$, for some $\pi_j \le 1$?

\item<2-> Convergence occurs, independent of the starting state, if:
\bce[\bf C1.]
\item<3-> Only a single recurrent class
\item<5-> such recurrent class is aperiodic
\ece

\item<4->[\bf C1.] For the case of multiple recurrent classes, one stays at the class including the starting state. 

\item<6->[\bf C2.] Divergent behavior for periodic recurrent classes. 

\eci

}
{
\centering
\mypic{0.8}{L9_class_ex.png}
\mypic{0.7}{L9_periodic_ex.png}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Balance Equation}

\plitemsep 0.1in
\bci
\item If $r_{ij}(n) \xrightarrow{n \rightarrow \infty} \pi_j$, for some $\pi_j \le 1,$
\aleq{
r_{ij}(n) &= \sum_{k=1}^m r_{ik}(n-1) p_{kj} \imp \onslide<2->{\redf{\pi_j = \sum_{k=1}^m \pi_k p_{kj}}} \ \onslide<3->{\text{\bluef{(Balance equation)}}}
}

\item<4-> \bluef{Normalization equation}
$$
\redf{\sum_{i=1}^m \pi_i = 1}
$$

\item<5-> Balance equation + Normalization equation $\imp$ Finding the steady-state probabilities $\{\pi_i \}.$

\eci


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example}

\plitemsep 0.1in
\bci

\item A two-state MC with: 
\aleq{
p_{11} = 0.8, & \quad p_{12} = 0.2,\cr
p_{21} = 0.6, & \quad p_{22} = 0.4.
}

\item Balance equation: 
\aleq{
\pi_1 &= \pi_1 p_{11} + \pi_2 p_{21} \cr
\pi_2 &= \pi_2 p_{22} + \pi_1 p_{12} 
}
\item Normalization equation: $\pi_1 + \pi_2 = 1$

\item The stationary distribution is: $\pi_1 = 0.25$, $\pi_2 = 0.75.$

\eci
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Stationary Distribution}

\plitemsep 0.1in
\bci

\item<2-> $\{ \pi_j \}$ is also called a \redf{stationary distribution}. Why?

\item<3-> \redf{Distribution}, because $\sum_{j=1}^m \pi_j =1.$

\item<4-> \redf{Stationary}, because, if you choose the starting state according to $\{\pi_j \},$ then 
\aleq{
\cprob{X_0 = j} = \pi_j, \quad j=1, \ldots, m \imp \onslide<5->{\cprob{X_1 = j} = \sum_{k=1}^m \cprob{X_0=k} p_{kj} =} \onslide<6->{\sum_{k=1}^m \pi_k p_{kj} = \pi_j}
}

\bci
\item<7-> Then, $\cprob{X_n = j} = \pi_j$, for all $n$ and $j.$

\item<8-> If the initial state is chosen according to $\{\pi_j \},$ the state at any future time will have the same distribution (i.e., the distribution does not change over time). 

\eci

\item<9-> We say that "the limiting distribution is equal to to the stationary distribution"

\eci


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Long-term Frequency Interpretation}

\plitemsep 0.1in
\bci

\item $\pi_j$: the long-term \bluef{expected fraction of time} that the state is equal to $j.$

\item<2-> Balance equation: $\sum_{k=1}^m \pi_k p_{kj} = \pi_j$ means:

\bci
\item<3->  The expected frequency $\pi_j$ of visits to $j$ is equal to the sum of the expected frequencies $\pi_k p_{kj}$ of transitions that lead to $j.$
\eci
\eci

\centering
\mypic{0.3}{L9_longtermfrequency.png}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Roadmap}

\plitemsep 0.1in

\bci 

% \item A lot of applications in engineering systems


% \bigskip

{\scriptsize
\item \bluef{Basics on Random Process}
\item \bluef{Bernoulli Process}
\item \bluef{Poisson Process}
\item \bluef{Use of Bernoulli and Poisson Processes}
}


\item \redf{Markov Chain}
\bci
\item \bluef{Definition, Transition Probability Matrix, State Transition Diagram}
\item \bluef{Classification of States}
\item \bluef{Steady-state Behaviors and Stationary Distribution}
\item \redf{Transient Behaviors}
\eci
\eci 

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Absorption Probability}

\mytwocols{0.6}
{
\small
\plitemsep 0.1in
\bci
\item<1-> \defi A state $k$ is \redf{absorbing,} if
$p_{kk}=1,$ and $p_{kj}=0$ for all $j\neq k.$

\onslide<2->{- states 1 and 6 are absorbing}

\item<3->[\redf{(Q)}] For a fixed absorbing state $s,$ the probability $a_i$ of reaching $s$, starting from a transient state $i$?

%\item Interested in the transient behavior of a MC.

\item<4-> Fix $s=6.$ 
\vspace{-0.3cm}
\aleq{
a_1 &=0, \quad a_6 =1 \cr
a_2 &= 0.2a_1 + 0.3a_2 + 0.4a_3 + 0.1 a_6 \cr
a_3 &= 0.2 a_2 + 0.8 a_6
}


\eci
}
{
\centering
\onslide<4->{\mypic{0.75}{L9_absorption_ex1.png}}
\onslide<5->{\mypic{0.8}{L9_absorption_ex2.png}}
}

\small
\onslide<5->{\redf{(Q)} What if there are some non-absorbing recurrent state? }

\onslide<6->{- Convert it into the one only with absorbing recurrent states (from (a) to (b)).}

\footnotetext{The notation $a_i$ should have dependence on $s,$ but we omit it for simplicity.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Expected Time to Any Absorbing State}

\mytwocols{0.2}
{
\small
\plitemsep 0.1in
\bci

\item[\redf{(Q)}] Starting from a transient state $i,$ expected number of transitions $\mu_i$ until absorption to any absorbing state?
% \aleq{
% \mu_i = \expect{\text{\# of transitions until absorption, starting from $i$}}
% }
\eci
}
{
\centering
\vspace{-0.5cm}
\mypic{0.75}{L9_spiderfly_onlyfigure.png}
% \mypic{0.8}{L9_absorption_ex2.png}
}

\small
\plitemsep 0.1in
\bci
\item<2-> Spider-fly example
\aleq{
\mu_1 &= \mu_4 =0 \quad \text{(for recurrent states)}\cr
\mu_2 &= \redf{1+} 0.4\mu_2 + 0.3 \mu_3, \quad \mu_3 = \redf{1 +} 0.3\mu_2 + 0.4\mu_3 \quad \text{(for transient states)}
}

\item<3-> For generalized description, please see the textbook (pp. 367). 

\eci

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Expected time to a particular recurrent state $s$}

- Assume a single recurrent class
\myvartwocols{0.2}{0.7}{0.29}
{
\small
\plitemsep 0.1in
\bci
\item<2->[\redf{(Q)}] \bluef{First passage time.} Starting from a $i,$ expected number of transitions $t_i$ to reach $s$ for the first time?

\item<4->[\redf{(Q)}] \bluef{First recurrence time.} Starting from a $s,$ expected number of transitions $t_s^\star$ to reach $s$ for the first time?

% \aleq{
% \mu_i = \expect{\text{\# of transitions until absorption, starting from $i$}}
% }
\eci
}
{
\centering
\vspace{-0.2cm}
\mypic{0.8}{L9_passage_ex.png}
% \mypic{0.8}{L9_absorption_ex2.png}
}
 \small
 \plitemsep 0.01in
 \bci
 \item<3-> Mean first passage time from 2 to 1
 \aleq{
 t_1 &= 0 \cr
 t_2 &= 1+ p_{21}t_1 + p_{22}t_2 = 1+ 0.4 t_2 \imp t_2 = 5/3
 }
 \item<5-> Mean first recurrence time from 1 to 1
 \aleq{
 t_1^\star &= 1+ p_{11}t_1 + p_{12}t_2 = 1+ 0 + 0.2\frac{5}{3} = \frac{4}{3}
 }

\item<6-> For generalized description, please see the textbook (pp. 368)
 \eci

\footnotetext{The notation $t_i$ should have the dependence on $s$, but we omit it for simplicity.}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}
\vspace{2cm}
\LARGE Questions?

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Review Questions}

\bce[1)]
\item Why do you think Markov chain (MC) is important?

\item What is the Markov property and its meaning? What's the key difference of MC from Bernoulli processes?

\item What are the limiting distribution and the stationary distribution of MCs?

\item How are you going to  compute the stationary distribution, if you are given a transition probability matrix?

\item What are recurrent and transient states in MC?


\ece

\end{frame}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}{Example}

% \plitemsep 0.1in

% \bci 
% \item Let $\set{E} = \{\ldots,-2,-1,0,1,2,\ldots \},$. Initially, $X_0 =
%   0,$ and $\forall n \leq 0,$
% \aleq{
%     \prob{X_{n+1}& = X_n +1 \vert X_n} = \prob{X_{n+1}= X_n-1 \vert X_n}
%     = 1/2. 
% }
  
% \item Draw transition diagram.
% \vspace{2.5cm}

% \item Check whether the above is Markov chain or not.

% \eci 
% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}{Definitions}

% \plitemsep 0.1in

% \bci 
% \item \defi Given HMC with transition matrix $P,$ $P^n$ is the $n$-step
%   transition matrix, i.e., $P^n=[p_{ij}(n)],$ where $p_{ij}(n)=$
%   probability of visiting $j$ in the $n$-step starting from $i$.

% \item \defi Node $i$ communicates with $j$ if there exist $n_1,n_2\geq
%   0,$ s.t. $p_{ij}(n_1)>0$ and $p_{ji}(n_2)>0$, denoted by $i
%   \leftrightarrow j.$

% \item \defi Communication defines ``equivalence class'' of HMC: (i) if
%   $i\leftrightarrow j,$ and $j \leftrightarrow k,$ then $i
%   \leftrightarrow k,$ and (ii) $i \leftrightarrow i$ (since $p_{ii}(0) =
%   1$).

% \item \defi A Markov chain is called {\red irreducible} if there is only one
%   communication class. {\blue Any state can be reachable starting from
%     any other state.}

% \item An example of a Markov chain that is not irreducible?

% \item Henceforth, we only consider a irreducible Markov chain.

% \eci 
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}{Period}

% \plitemsep 0.1in

% \bci 
% \item The period of $d(i)$ of state $i \in \set{E}$ is defined by 
% $    d(i) = gcd\{n: p_{ii}(n) >0\}.$


% \item We call $i$ {\red periodic} if $d(i)>1$ and {\red aperiodic} if $d(i)=1.$

% \item An irreducible HMC is called {\red aperiodic} if all of its period is
%   aperiodic.

% \item Period is a class property

% \bci
% \item If $i$ and $j$ communicate, then
%   they have the same period. 
 
% \item Thus, it suffices to check one state's
%   aperiodicity for a irreducible Markov chain, if you want to check the
%   aperiodicity of the entire Markov chain. 

% % \item \redf{Proof.}  As $i \leftrightarrow j,$ there exists integers $N,M,$ such that
% % $p_{ij}(M)>0$ and $p_{ji}(N) >0.$ For any $k \geq 1,$
% % \aleq{
% %   p_{ii}(M+nk +N) \geq p_{ij}(M) (p_{jj}(k))^n p_{ji}(N). \text{\qed}
% % }
% % Thus, for any $k\geq 1,$ such that $p_{jj}(k) >0,$ we have
% % $p_{ii}(M+nk+N) >0$ for all $n\geq 1.$ Then, $d_i$ divides $M+nk+_N$ for
% % all $n\geq 1,$ and in particular, $d_i$ divides $k.$ Thus, $d_i$ divides
% % all $k,$ such that $p_{jj}(k) >0,$ in particular, $d_i$ divides $d_j.$
% % By symmetry, $d_j$ divides $d_i.$ Thus, $d_i = d_j.$

% \eci

% \item Example. Two states 1 and 2. $p_{12} = 1$ and $p_{21} = 1.$

% \eci 
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}{Recurrence}

% \plitemsep 0.05in

% \bci 
% \item \defi Let $T_i = \min \{k\geq 1 \vert X_{k}=i \}.$ Then, mentioned
%   earlier, $T_i$ is a
%   stopping time. State $i$ is called {\red recurrent} if $\probi{i}{T_i} 
%   \triangleq \prob{T_i < \infty | X_0=i} = 1,$ otherwise called {\red transient}.

% \item Staring from a state $i$, I will return to the state $i$ within a
%   finite time with probability 1.

% \item Let $f_{ii}^{(n)} = \prob{T_i = n \mid X_o = i},$ which is the
%   probability that the first return time from $i$ to $i$ is $n.$ Then,
%   from the definition {\red recurrent} if $\sum_{n=1}^\infty f_{ii}^{(n)} = 1,$ and {\red transient} if $\sum_{n=1}^\infty f_{ii}^{(n)} < 1.$

% \item \redf{Lemma.} Let $N_i = \sum_{n \geq 1} {\bf1}_{\{X_n=i\}}$ be the number of
%   times state $i$ is visited. Then,
% \aleq{
%     \probi{i}{T_i < \infty} = 1, \quad \text{iff} \quad \expecti{i}{N_i}= \infty. 
% }
% In other words, recurrent state $i$ iff I visit state $i$ infinite times.


% % \redf{Proof.} Let $f_{ii} = \sum_{n=1}^\infty f_{ii}^{(n)}  = \probi{i}{T_i < \infty}.$ Let $0=\tau_0,
% %   \tau_1, \ldots,$ be times of visit of state $i.$ Now, suppose $f_{ii}
% %   < 1.$ For $r \geq 1,$ using strong Markov property, 
% %   \begin{eqnarray*}
% %     \probi{i}{N_i = r} = \probi{i}{\tau_1 < \infty, \tau_2-\tau_1 <
% %       \infty, \ldots, \tau_{r+1} - \tau_r = \infty} \cr
% %     = \Big (\prod_{j=1}^r \probi{i}{\tau_j - \tau_{j-1}< \infty} \big)
% %     \probi{i}{\tau_{r+1} - \tau_r = \infty } = f_{ii}^r (1-f_{ii}).
% %   \end{eqnarray*}
% %   Thus, $\expecti{i}{N_i} = \sum_r rf_{ii}^r(1-f_{ii}) = 1/(1-f_{ii}).$ \qed

% % \item Note that $\expecti{i}{N_i} =\sum_{n=0}^\infty p_{ii}(n).$

% \item \redf{Lemma.} For an irreducible HMC, if some $i \in \set{E}$ is recurrent
%   then any other $j \in \set{E}$ is recurrent. 
% {\blue Recurrence is a property of the equivalent communication class}

% % \item \redf{Proof.}
% % As $i \leftrightarrow j,$ there exists integers $N,M,$ such that
% % $p_{ij}(M)>0$ and $p_{ji}(N) >0.$ We have that:
% % \begin{eqnarray*}
% %   p_{ii}(M+n +N) \geq \alpha \times p_{jj}(n),
% % \end{eqnarray*}
% % where $\alpha = p_{ij}(M) p_{ji}(N).$
% % Similarly, we get:
% % \begin{eqnarray*}
% %  p_{jj}(N+n +M) \geq \alpha \times p_{ii}(n).
% % \end{eqnarray*}
% % The above means that $\sum_{n=0}^\infty p_{ii}(n)$ and
% % $\sum_{n=0}^\infty p_{jj}(n)$ either both converge or both diverge.
% % \qed 

% \eci
% \end{frame}



\end{document}
